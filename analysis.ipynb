{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from cdlib import *\n",
    "from cdlib import viz\n",
    "from collections import OrderedDict\n",
    "def read_com(f_c):\n",
    "    #返回按照社团中节点数量排序的社团-节点字典\n",
    "    com = {}\n",
    "    coms = OrderedDict()\n",
    "    with open(f_c, 'r', encoding='utf-8') as f:\n",
    "        for n in f.readlines():\n",
    "            n_c = n.strip('\\n').split(':')\n",
    "            n = n_c[0]\n",
    "            # daikan\n",
    "            c = n_c[1].split(' ')\n",
    "            com[n] = c\n",
    "    com = dict(sorted(com.items(), reverse=True, key=lambda k: len(k[1])))\n",
    "    for i, c in enumerate(com.values()):\n",
    "        coms[i] = c\n",
    "    \n",
    "    return coms\n",
    "def turnto_community_graph(graph, partition, figsize=(8, 8), node_size=200, plot_overlaps=False, plot_labels=False):\n",
    "    \"\"\"\n",
    "        Plot a algorithms-graph with node color coding for communities.\n",
    "\n",
    "        :param graph: NetworkX/igraph graph\n",
    "        :param partition: NodeClustering object\n",
    "        :param figsize: the figure size; it is a pair of float, default (8, 8)\n",
    "        :param node_size: int, default 200\n",
    "        :param plot_overlaps: bool, default False. Flag to control if multiple algorithms memberships are plotted.\n",
    "        :param plot_labels: bool, default False. Flag to control if node labels are plotted.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        >>> from cdlib import algorithms, viz\n",
    "        >>> import networkx as nx\n",
    "        >>> g = nx.karate_club_graph()\n",
    "        >>> coms = algorithms.louvain(g)\n",
    "        >>> viz.plot_community_graph(g, coms)\n",
    "        \"\"\"\n",
    "\n",
    "#     cms = partition.communities\n",
    "\n",
    "    node_to_com = {}\n",
    "    com_size={}\n",
    "    for cid, com in partition.items():\n",
    "        com_size[cid]=len(com)\n",
    "        for node in com:\n",
    "            if node not in node_to_com:\n",
    "                node_to_com[node] = cid\n",
    "            else:\n",
    "                # duplicating overlapped node\n",
    "                alias = \"%s_%s\" % (node, cid)\n",
    "                node_to_com[alias] = cid\n",
    "                edges = [(alias, y) for y in graph.neighbors(node)]\n",
    "                graph.add_edges_from(edges)\n",
    "\n",
    "    # handling partial coverage\n",
    "    s = nx.subgraph(graph, node_to_com.keys())\n",
    "\n",
    "    # algorithms graph construction\n",
    "    c_graph = induced_graph(node_to_com, s)\n",
    "    node_cms = [[node] for node in c_graph.nodes()]\n",
    "    viz.plot_network_clusters(c_graph, NodeClustering(node_cms, None, \"\"), nx.spring_layout(c_graph), figsize=figsize,\n",
    "                                 node_size=node_size, plot_overlaps=plot_overlaps, plot_labels=plot_labels)\n",
    "\n",
    "    return c_graph,com_size\n",
    "\n",
    "def induced_graph(partition, graph, weight=\"weight\"):\n",
    "    \"\"\"Produce the graph that nodes are the communities\n",
    "\n",
    "    there is a link of weight w between communities if the sum of the weights\n",
    "    of the links between their elements is w\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    partition : dict\n",
    "       a dictionary where keys are graph nodes and  values the part the node\n",
    "       belongs to\n",
    "    graph : networkx.Graph\n",
    "        the initial graph\n",
    "    weight : str, optional\n",
    "        the key in graph to use as weight. Default to 'weight'\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    g : networkx.Graph\n",
    "       a networkx graph where nodes are the parts\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> n = 5\n",
    "    >>> g = nx.complete_graph(2*n)\n",
    "    >>> part = dict([])\n",
    "    >>> for node in g.nodes() :\n",
    "    >>>     part[node] = node % 2\n",
    "    >>> ind = induced_graph(part, g)\n",
    "    >>> goal = nx.Graph()\n",
    "    >>> goal.add_weighted_edges_from([(0,1,n*n),(0,0,n*(n-1)/2), (1, 1, n*(n-1)/2)])  # NOQA\n",
    "    >>> nx.is_isomorphic(int, goal)\n",
    "    True\n",
    "    \"\"\"\n",
    "    ret = nx.Graph()\n",
    "    ret.add_nodes_from(partition.values())\n",
    "\n",
    "    for node1, node2, datas in graph.edges(data=True):\n",
    "        edge_weight = datas.get(weight, 1)\n",
    "        com1 = partition[node1]\n",
    "        com2 = partition[node2]\n",
    "        w_prec = ret.get_edge_data(com1, com2, {weight: 0}).get(weight, 1)\n",
    "        ret.add_edge(com1, com2, **{weight: w_prec + edge_weight})\n",
    "\n",
    "    return ret\n",
    "def add_node_weight(G,node_att):\n",
    "    for k,v in node_att.items():\n",
    "        G.nodes[k]['weight']=v\n",
    "    return G\n",
    " #将划分得到的图转化为以社团为节点的图，主要改变了cdlib中的函数\n",
    "g_list=['PRPER','PRAB','PRFLUIDS','PRI','PRSTPER','PRAPPLIED','PRX','PRSTAB','RMP',\n",
    "       'PRE','PR','PRC','PRA','PRD']\n",
    "fgs='F:/aps_analysis/graph_label/graph/'\n",
    "fcs='F:/aps_analysis/graph_label/community/'\n",
    "fo='F:/aps_analysis/graph_label/output_new/com_graph/'\n",
    "font1 = {'family' : 'Times New Roman',\n",
    "             'weight' : 'normal',\n",
    "             'size'   : 10}\n",
    "for g in g_list:\n",
    "    fg=fgs+g+'.gexf'\n",
    "    fc=fcs+g+'.txt'\n",
    "    G=nx.read_gexf(fg)\n",
    "    coms=read_com(fc)\n",
    "#     partition=NodeClustering(list(coms.values()), None, \"\")\n",
    "    c_g,com_size=turnto_community_graph(G,coms)\n",
    "    p=nx.selfloop_edges(c_g)\n",
    "    c_g.remove_edges_from(p)\n",
    "    c_g=add_node_weight(c_g,com_size)\n",
    "    nx.write_gexf(c_g,fo+g+'_com.gexf')\n",
    "    plt.title(g,fontdict=font1,y=-0.1)\n",
    "    plt.savefig(fo+g+'_com.png',dpi=300)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制社团节点标签\n",
    "import json\n",
    "\n",
    "fls='F:/aps_analysis/graph_label/output_new/com_label_order/'\n",
    "fws='F:/aps_analysis/graph_label/output_new/com_word/'\n",
    "fo='F:/aps_analysis/graph_label/output_new/add_com_label/'\n",
    "# fo='F:/aps_analysis/graph_label/output_new/add_com_label_nomax/'\n",
    "g_list=['PRPER','PRAB','PRFLUIDS','PRI','PRSTPER','PRAPPLIED','PRX','PRSTAB','RMP',\n",
    "       'PRE','PR','PRC','PRA','PRD']\n",
    "for g in g_list:\n",
    "    fl=fls+g+'.json'\n",
    "    fw=fws+g+'.json'\n",
    "    with open(fl,'r',encoding='utf-8')as f:\n",
    "        l=json.load(f)\n",
    "    with open(fw,'r',encoding='utf-8')as f1:\n",
    "        w=json.load(f1)\n",
    "    new_l={}\n",
    "    for k,v in l.items():\n",
    "        d={}\n",
    "        s=w[k]\n",
    "        max_k1=sorted(v.items(),reverse=True,key= lambda k:k[1])[0][0]\n",
    "        for k1,v1 in v.items():\n",
    "            d[k1]=s.get(k1,0)+v1\n",
    "#             if k1==max_k1:\n",
    "#                 d[k1]=v1\n",
    "#             else:   \n",
    "#                 d[k1]=s.get(k1,0)+v1\n",
    "        order_s=sorted(s.items(),reverse=True,key= lambda k:k[1])\n",
    "#         print(order_s)\n",
    "        i=0\n",
    "        m=len(order_s)\n",
    "        while len(d)<21:\n",
    "            if order_s[i][0] in d.keys():\n",
    "                pass\n",
    "            else:\n",
    "                d[order_s[i][0]]=order_s[i][1]\n",
    "            i=i+1\n",
    "            if i==m:\n",
    "                break\n",
    "        d=dict(sorted(d.items(),reverse=True,key= lambda k:k[1]))\n",
    "        new_l[k]=d\n",
    "    with open(fo+g+'.json','w',encoding='utf-8')as f2:\n",
    "        json.dump(new_l,f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成词云图\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "def read_text(ft):\n",
    "    with open(ft,'r',encoding='utf-8')as f:\n",
    "        data=json.load(f)\n",
    "    return data\n",
    "def getpart(data,n_list):\n",
    "    dt={}\n",
    "    for n in n_list:\n",
    "        dt[n]=data[n]\n",
    "    return dt\n",
    "\n",
    "def label_wordcloud(fileout,name,label,image_file):\n",
    "    #com_label  {com:{label:fre}}\n",
    "    \n",
    "        # print(label)\n",
    "\n",
    "        # read the mask image\n",
    "        # taken from\n",
    "        # http://www.stencilry.org/stencils/movies/alice%20in%20wonderland/255fk.jpg\n",
    "        alice_mask = np.array(Image.open(image_file))\n",
    "        stopwords = set(STOPWORDS)\n",
    "        # stopwords.add(\"said\")\n",
    "        wc = WordCloud(background_color=\"white\", max_words=15, \n",
    "#                        width=20,height=16,\n",
    "#             mask=alice_mask,\n",
    "#           max_font_size=36,\n",
    "            stopwords=stopwords, contour_width=3, contour_color='white',\n",
    "#           colormap='gist_heat'\n",
    "            colormap='viridis'\n",
    "#                        colormap='inferno'\n",
    "                      )\n",
    "        # generate word cloud\n",
    "        wc.generate_from_frequencies(label)\n",
    "\n",
    "        # store to file\n",
    "#         wc.to_file(fileout+'{}_wordcloud.png'.format(com.split('.')[-1]))\n",
    "        # show\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "#         plt.figure()\n",
    "#         plt.imshow(alice_mask, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "#         plt.axis(\"off\")\n",
    "        plt.savefig(fileout+'{}_wordcloud.png'.format(name),dpi=500)\n",
    "        plt.show()\n",
    "prstab=[\"10.1103/PhysRevSTAB.13.092803\",\"10.1103/PhysRevSTAB.7.074401\",\"10.1103/PhysRevSTAB.17.121001\",\n",
    "        \"10.1103/PhysRevSTAB.6.104402\",\"10.1103/PhysRevSTAB.16.010705\",\"10.1103/PhysRevSTAB.6.101301\",\n",
    "       \"10.1103/PhysRevSTAB.5.084001\",\"10.1103/PhysRevSTAB.13.080401\",\"10.1103/PhysRevSTAB.18.091001\",\n",
    "       \"10.1103/PhysRevSTAB.13.121004\"]\n",
    "rmp=[\"10.1103/RevModPhys.77.721\",\"10.1103/RevModPhys.79.135\", \"10.1103/RevModPhys.25.390\",\n",
    "    \"10.1103/RevModPhys.59.671\",\"10.1103/RevModPhys.46.597\"]\n",
    "prx=[\"10.1103/PhysRevX.8.011040\",\"10.1103/PhysRevX.7.021003\",\"10.1103/PhysRevX.7.011014\",\n",
    "    \"10.1103/PhysRevX.4.021017\",\"10.1103/PhysRevX.7.011001\"]\n",
    "image_file='D:/Backup Plus/slpa-dataset/slpa_compare_input/logo.png'\n",
    "# fo='F:/aps_analysis/graph_label/output_new/wordcloud/prstab/adjust/'\n",
    "# fi='F:/aps_analysis/graph_label/output_new/add_com_label_nomax - adjust/PRSTAB.json'\n",
    "fo='F:/aps_analysis/graph_label/output_new/prstab/'\n",
    "fi='F:/aps_analysis/graph_label/output_new/add_com_label_nomax - adjust/PRSTAB.json'\n",
    "\n",
    "data=read_text(fi)\n",
    "dt=getpart(data,prstab)\n",
    "for c,v in dt.items():\n",
    "    name=c.split('.')[-1]\n",
    "    label_wordcloud(fo,name,v,image_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
